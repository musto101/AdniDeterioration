abline(fit)
test <- data.frame(year = 2026)
predict(fit, test)
#use model to get predicted values
pred <- predict(fit)
ix <- sort(x, index.return=T)$ix
#add polynomial curve to plot
lines(x[ix], pred[ix], col='red', lwd=2)
#use model to get predicted values
plot(earnings$year, earnings$salary, pch=16, cex=1.5)
#use model to get predicted values
pred <- predict(fit)
ix <- sort(earnings$year, index.return=T)$ix
#add polynomial curve to plot
lines(earnings$year[ix], pred[ix], col='red', lwd=2)
test <- data.frame(year = 2026)
predict(fit, test)
test <- data.frame(year = 2049)
predict(fit, test)
test <- data.frame(year = 2023:2049)
View(test)
pred <- predict(fit, test)
plot(test$year, pred)
options(scipen = 10000)
plot(test$year, pred)
plot(test$year, pred, type = 'l')
df %>%
ggplot(aes(x=test$year, y=pred)) +
geom_line()+
scale_y_continuous(labels=scales::dollar_format())
library(ggplot2)
ggplot(aes(x=test$year, y=pred)) + geom_line()+
scale_y_continuous(labels=scales::dollar_format())
predicted <- data.frame(year = test$year, predicted_salary = pred)
ggplot(predicted, aes(x = year, y = predicted_salary)) + geom_line()+
scale_y_continuous(labels=scales::dollar_format())
ggplot(predicted, aes(x = year, y = predicted_salary)) + geom_line()+
scale_y_continuous(labels=scales::pound_format())
ggplot(predicted, aes(x = year, y = predicted_salary)) + geom_line()+
scale_y_continuous(labels=scales::dollar_format(suffix = '£'))
ggplot(predicted, aes(x = year, y = predicted_salary)) + geom_line()+
scale_y_continuous(labels=scales::dollar_format(prefix = '£'))
fit2 <- lm(salary ~ year, earnings)
pred2 <- predict(fit2, test)
predicted2 <- data.frame(year = test$year, predicted_salary = pred2)
View(predicted2)
View(predicted2)
devtools::build()
devtools::check()
dat <- read.csv('data/mci_progress.csv', stringsAsFactors = T)
dat <- read.csv('data/adni_slim.csv', stringsAsFactors = T)
dat$X <- NULL
dat <- preprocessing(dat, 0.5, clinGroup = 'CN')
library(caret)
library(broom)
library(tidyverse)
library(performanceEstimation)
library(doParallel)
library(pROC)
dat <- preprocessing(dat, 0.5, clinGroup = 'CN')
pre <- Sys.time()
dat <- read.csv('data/adni_slim.csv', stringsAsFactors = T)
dat$X <- NULL
dat <- preprocessing(dat, 0.5, clinGroup = 'CN')
dat <- read.csv('data/adni_slim.csv', stringsAsFactors = T)
dat$X <- NULL
str(dat$last_DX)
missing.perc <- apply(dat, 2, function(x) sum(is.na(x))) / nrow(dat)
dat <- dat[, which(missing.perc < perc)]
perc = 0.5
dat <- dat[, which(missing.perc < perc)]
dat <- dat[dat$PTMARRY != 'Unknown',]
dat <- dat[dat$last_visit > 0,]
y <- dat %>%
mutate_all(funs(ifelse(is.na(.), 1, 0)))
blah <- y %>%
select_if(function(col) is.numeric(col) && sum(col) == 0) # sanity check
y <- y %>%
select_if(negate(function(col) is.numeric(col) && sum(col) == 0))
names(y) <- paste0(names(y), '_na')
dat <- cbind(dat, y)
str(dat$last_DX)
dummies <- dummyVars(last_DX ~., data = dat)
data_numeric <- predict(dummies, newdata= dat)
data_numeric <- as.data.frame(data_numeric)
data_numeric <-data.frame(dat$last_DX, data_numeric)
names(data_numeric)[1] <- 'last_DX'
data_numeric$X <- NULL
str(dat$last_DX)
data_numeric <- predict(dummies, newdata= dat)
data_numeric <- as.data.frame(data_numeric)
data_numeric <-data.frame(dat$last_DX, data_numeric)
names(data_numeric)[1] <- 'last_DX'
data_numeric$X <- NULL
str(data_numeric$last_DX)
clinGroup = 'CN'
if (clinGroup == 'CN') {
cn_progress <- data_numeric[data_numeric$DXCN == 1,]
cn_progress$last_DX <- factor(ifelse(cn_progress$last_DX == 'CN',
'CN', 'MCI_AD'),
levels = c('CN', 'MCI_AD'))
cn_progress$DXCN <- NULL
cn_progress$DXDementia <- NULL
cn_progress$DXMCI <- NULL
} else if (clinGroup == 'MCI') {
cn_progress <- data_numeric[data_numeric$DXMCI == 1,]
cn_progress$last_DX <- factor(ifelse(cn_progress$last_DX == 'Dementia',
'Dementia', 'CN_MCI'),
levels = c('CN_MCI', 'Dementia'))
cn_progress$DXCN <- NULL
cn_progress$DXDementia <- NULL
cn_progress$DXMCI <- NULL
} else {
stop('clinGroup needs to be either CN or MCI. Please try again.')
}
cn_progress <- data_numeric[data_numeric$DXCN == 1,]
View(dat)
table(dat$DX)
View(data_numeric)
data_numeric[data_numeric$DXCN == 1,]
cn_progress <- data_numeric[data_numeric$DX.CN == 1,]
cn_progress$last_DX <- factor(ifelse(cn_progress$last_DX == 'CN',
'CN', 'MCI_AD'),
levels = c('CN', 'MCI_AD'))
#' preprocessing from adni_slim data
#'
#' preprocesses the adni_slim data by removing columns with perc missing values
#' and filters on the relevant clinical group clinGroup. Also dummies and records
#' location of missing values.
#'
#' @param dat is a dataframe
#' @param perc is the percentage of missing values, where if
#' column missing > perc, column is removed.
#' @param clinGroup is the clinical group desired to filter on.
#' @return It returns a dataframe of the preprocessed data
#' @export
#'
preprocessing <- function(dat, perc, clinGroup) {
missing.perc <- apply(dat, 2, function(x) sum(is.na(x))) / nrow(dat)
dat <- dat[, which(missing.perc < perc)]
dat <- dat[dat$PTMARRY != 'Unknown',]
dat <- dat[dat$last_visit > 0,]
y <- dat %>%
mutate_all(funs(ifelse(is.na(.), 1, 0)))
blah <- y %>%
select_if(function(col) is.numeric(col) && sum(col) == 0) # sanity check
y <- y %>%
select_if(negate(function(col) is.numeric(col) && sum(col) == 0))
names(y) <- paste0(names(y), '_na')
dat <- cbind(dat, y)
dummies <- dummyVars(last_DX ~., data = dat)
data_numeric <- predict(dummies, newdata= dat)
data_numeric <- as.data.frame(data_numeric)
data_numeric <-data.frame(dat$last_DX, data_numeric)
names(data_numeric)[1] <- 'last_DX'
data_numeric$X <- NULL
if (clinGroup == 'CN') {
cn_progress <- data_numeric[data_numeric$DX.CN == 1,]
cn_progress$last_DX <- factor(ifelse(cn_progress$last_DX == 'CN',
'CN', 'MCI_AD'),
levels = c('CN', 'MCI_AD'))
cn_progress$DX.CN <- NULL
cn_progress$DX.Dementia <- NULL
cn_progress$DX.MCI <- NULL
} else if (clinGroup == 'MCI') {
cn_progress <- data_numeric[data_numeric$DX.MCI == 1,]
cn_progress$last_DX <- factor(ifelse(cn_progress$last_DX == 'Dementia',
'Dementia', 'CN_MCI'),
levels = c('CN_MCI', 'Dementia'))
cn_progress$DX.CN <- NULL
cn_progress$DX.Dementia <- NULL
cn_progress$DX.MCI <- NULL
} else {
stop('clinGroup needs to be either CN or MCI. Please try again.')
}
return(cn_progress)
}
dat_processed <- preprocessing(dat, 0.5, clinGroup = 'CN')
dat <- read.csv('data/adni_slim.csv', stringsAsFactors = T)
dat$X <- NULL
dat_processed <- preprocessing(dat, 0.5, clinGroup = 'CN')
str(dat_processed)
grid <- expand.grid(lambda = seq(0, 5, 1), alpha = seq(0, 1, 0.1))
source(model_deter())
source('R/model_deter.r'
)
model_deter(dat_processed, model = 'glmnet', grid = grid, mcRep = 1, clinGroup = 'CN')
#' modelling deterioration data
#'
#' This funcion will model the adni data, dat, which will be modelled using the
#' specified ML technique model, with hyperparameter tuning defined with values
#' found in grid.
#'
#' @param dat a dataframe.
#' @param model is a string indicating the model to be used.
#' @param grid is a matrix of hyperparam tuning values.
#' @param mcRep is a numeric value indicating the number of iterations of
#' bootstrapping are desired.
#' @param clinGroup is a string indicating the clinical group of interest.
#' @return it saves a csv of probabilities and a csv of summary statistics.
#' @export
#'
model_deter <- function(dat, model, grid, mcRep, clinGroup) {
mcPerf <- data.frame(ROC = numeric(), Sens = numeric(), Spec = numeric(),
Accuracy = numeric(), Kappa = numeric())
ctrl <- trainControl(method = 'cv', number = 5, classProbs = T,
summaryFunction = twoClassSummary, sampling = 'smote',
verboseIter = F)
cl <- makeCluster(detectCores())
# cl <- makeCluster(7)
registerDoParallel(cl)
#repeat mcRep times
for (j in 1:mcRep) {
# create nrfolds folds and start outer CV
print(j)
nrfolds = nrow(dat)/3
folds <- createFolds(dat$last_DX, k = nrfolds)
totalnewPrediction <- c(NA)
length(totalnewPrediction) <- nrow(dat)
totalprobabilities <- c(NA)
length(totalprobabilities) <- nrow(dat)
for (n in 1:nrfolds){
training <- dat[-folds[[n]],]
test <- dat[folds[[n]],]
# # missing values imputation
impute_train <- preProcess(training, method = "knnImpute")
training <- predict(impute_train, training)
impute_test <- preProcess(rbind(training[,-1], test[,-1]),
method = "knnImpute")
test[,-1] <- predict(object = impute_test, test[,-1])
booted_training <- bootstrapping(training, n = 1000)
# tuning
ml_model <- train(last_DX ~ .,
data = booted_training, method = model,
metric = "ROC",
#na.action = na.pass,
#preProcess = c("knnImpute", "scale", "center"),
tuneGrid = grid, trControl = ctrl)
### post processing cross evaluation
# ROC
evalResults <- data.frame(last_DX = test$last_DX)
evalResults$rf <- predict(ml_model, test, type = "prob")[, 1]
evalResults$newPrediction <- predict(ml_model, test)
totalnewPrediction[folds[[n]]] <- evalResults$newPrediction
totalprobabilities[folds[[n]]] <- evalResults$rf
}
v <- post_modelling_proc(dat, totalnewprediction, totalprobabilities,
clinGroup, mcPerf = mcPerf)
names(v) <- c('ROC', 'Sens', 'Spec', 'Accuracy', 'Kappa')
v <- data.frame(t(v))
mcPerf <- rbind(mcPerf, v)
}
write.csv(mcPerf, paste0('data/', model, '_', clinGroup, '_',
'100_McPerf.csv'))
write.csv(totalprobabilities, paste0('data/', model, '_', clinGroup, '_',
'McPerf_probabilities.csv'))
print('model run successfully!')
}
model_deter(dat_processed, model = 'glmnet', grid = grid, mcRep = 1, clinGroup = 'CN')
#' modelling deterioration data
#'
#' This funcion will model the adni data, dat, which will be modelled using the
#' specified ML technique model, with hyperparameter tuning defined with values
#' found in grid.
#'
#' @param dat a dataframe.
#' @param model is a string indicating the model to be used.
#' @param grid is a matrix of hyperparam tuning values.
#' @param mcRep is a numeric value indicating the number of iterations of
#' bootstrapping are desired.
#' @param clinGroup is a string indicating the clinical group of interest.
#' @return it saves a csv of probabilities and a csv of summary statistics.
#' @export
#'
model_deter <- function(dat, model, grid, mcRep, clinGroup) {
mcPerf <- data.frame(ROC = numeric(), Sens = numeric(), Spec = numeric(),
Accuracy = numeric(), Kappa = numeric())
ctrl <- trainControl(method = 'cv', number = 5, classProbs = T,
summaryFunction = twoClassSummary, sampling = 'smote',
verboseIter = F)
cl <- makeCluster(detectCores())
# cl <- makeCluster(7)
registerDoParallel(cl)
#repeat mcRep times
for (j in 1:mcRep) {
# create nrfolds folds and start outer CV
print(j)
nrfolds = nrow(dat)/3
folds <- createFolds(dat$last_DX, k = nrfolds)
totalnewPrediction <- c(NA)
length(totalnewPrediction) <- nrow(dat)
totalprobabilities <- c(NA)
length(totalprobabilities) <- nrow(dat)
for (n in 1:nrfolds){
training <- dat[-folds[[n]],]
test <- dat[folds[[n]],]
# # missing values imputation
impute_train <- preProcess(training, method = "knnImpute")
training <- predict(impute_train, training)
impute_test <- preProcess(rbind(training[,-1], test[,-1]),
method = "knnImpute")
test[,-1] <- predict(object = impute_test, test[,-1])
booted_training <- bootstrapping(training, n = 1000)
# tuning
ml_model <- train(last_DX ~ .,
data = booted_training, method = model,
metric = "ROC",
#na.action = na.pass,
#preProcess = c("knnImpute", "scale", "center"),
tuneGrid = grid, trControl = ctrl)
### post processing cross evaluation
# ROC
evalResults <- data.frame(last_DX = test$last_DX)
evalResults$rf <- predict(ml_model, test, type = "prob")[, 1]
evalResults$newPrediction <- predict(ml_model, test)
totalnewPrediction[folds[[n]]] <- evalResults$newPrediction
totalprobabilities[folds[[n]]] <- evalResults$rf
}
v <- post_modelling_proc(dat, totalnewPrediction, totalprobabilities,
clinGroup, mcPerf = mcPerf)
names(v) <- c('ROC', 'Sens', 'Spec', 'Accuracy', 'Kappa')
v <- data.frame(t(v))
mcPerf <- rbind(mcPerf, v)
}
write.csv(mcPerf, paste0('data/', model, '_', clinGroup, '_',
'100_McPerf.csv'))
write.csv(totalprobabilities, paste0('data/', model, '_', clinGroup, '_',
'McPerf_probabilities.csv'))
print('model run successfully!')
}
model_deter(dat_processed, model = 'glmnet', grid = grid, mcRep = 1,
clinGroup = 'CN')
devtools::build()
#' Post modelling processing
#'
#' This function will work in the outer loop of the bootstrap and spit out
#' summary statistics for the model.
#'
#' @param dat a dataframe.
#' @param totalnewprediction a matrix of predictions.
#' @param totalprobabilities a matrix of prediction probabilities.
#' @param clinGroup a string indicating the clinical group of interest.
#' @param mcPerf is the performance from the pervious iteration.
#' @return it returns a vector of five summary statistics.
#' @export
#'
post_modelling_proc <- function(dat, totalnewPrediction, totalprobabilities,
clinGroup, mcPerf) {
if (clinGroup == 'CN') {
totalnewPrediction <- factor(totalnewPrediction, levels = c('CN', 'MCI_AD'))
# confusion matrix all dataset
cm <- confusionMatrix(totalnewPrediction, dat$last_DX, positive = 'MCI_AD')
cm
# perf
rfROCfull <- roc(dat$last_DX, totalprobabilities, levels = c('CN', 'MCI_AD'))
rfROC <- roc(response = dat$last_DX, totalprobabilities,
levels = c('CN', 'MCI_AD'))
rfThresh <- coords(rfROC, x = 'best', best.method = 'youden')
pred <- ifelse(totalprobabilities >= rfThresh[1, 1], 'MCI_AD', 'CN')
} else if(clinGroup == 'MCI') {
totalnewPrediction <- factor(totalnewPrediction, levels = c('Dementia',
'CN_MCI'))
dat$last_DX = factor(dat$last_DX, levels = c('Dementia','CN_MCI'))
# confusion matrix all dataset
cm <- confusionMatrix(totalnewPrediction, dat$last_DX, positive = 'Dementia')
rfROCfull <- roc(dat$last_DX, totalprobabilities, levels = c('Dementia',
'CN_MCI'))
rfROC <- roc(response = dat$last_DX, totalprobabilities,
levels = c('Dementia', 'CN_MCI'))
rfThresh <- coords(rfROC, x = 'best', best.method = 'youden')
pred <- ifelse(totalprobabilities >= rfThresh[1, 1], 'CN_MCI','Dementia')
} else {
stop('clinGroup needs to be either CN or MCI. Please try again.')
}
sen <- sensitivity(factor(pred), (dat$last_DX))
speci <- specificity(factor(pred), (dat$last_DX))
kp <- confusionMatrix(factor(pred), (dat$last_DX))[[3]][2]
acc <- confusionMatrix(factor(pred), (dat$last_DX))[[3]][1]
v <- c(ROC = auc(rfROCfull), sen, speci, acc, kp)
names(v) <- c('ROC', 'Sens', 'Spec', 'Accuracy', 'Kappa')
v <- data.frame(t(v))
mcPerf <- rbind(mcPerf, v)
return(mcPerf)
}
model_deter(dat_processed, model = 'glmnet', grid = grid, mcRep = 1,
clinGroup = 'CN')
devtools::check()
6300 * 1.23
(6300 * 1.23) - 4250.60
((6300 * 1.23) - 4250.60)+2322.99
(((6300 * 1.23) - 4250.60)+2322.99) * 12
((((6300 * 1.23) - 4250.60)+2322.99) * 12) + 29000
(((((6300 * 1.23) - 4250.60)+2322.99) * 12) + 29000) +26000
((((((6300 * 1.23) - 4250.60)+2322.99) * 12) + 29000) +26000) - 17500
550000 * 0.15
1981/2
17500 + 5000
242/1154
242/115
170/2
1884.39 * 12
(1884.39 * 12) + 27000
2/3
library(lubridate)
library(caret)
library(lubridate)
library(caret)
## logistic regression
dat <- read.csv('data/one_day.csv')
setwd("~/workspace/TemporalPythonTechTest")
library(lubridate)
library(caret)
## logistic regression
dat <- read.csv('data/one_day.csv')
dat$created_at <- as.numeric(as_datetime(dat$created_at))
dat$timestamp <- as.numeric(as_datetime(dat$timestamp))
dat$updated_at <- as.numeric(as_datetime(dat$updated_at))
dat$created_from <- NULL # Its only got one value
dat$project_id <- as.character(dat$project_id)
write.csv(dat, 'data/one_day_pp.csv')
View(dat)
library(lubridate)
library(caret)
## logistic regression
dat <- read.csv('data/one_day.csv')
dat$created_at <- as.numeric(as_datetime(dat$created_at))
dat$timestamp <- as.numeric(as_datetime(dat$timestamp))
dat$updated_at <- as.numeric(as_datetime(dat$updated_at))
dat$created_from <- NULL # Its only got one value
dat$project_id <- as.character(dat$project_id)
write.csv(dat, 'data/one_day_pp.csv')
library(lubridate)
library(caret)
## logistic regression
dat <- read.csv('data/one_day.csv')
as_time(dat$created_at)
strptime(dat$created_at)
strptime(dat$created_at, format = '%H:%M:%S')
as_datetime(dat$created_at)
format(as_datetime(dat$created_at),
format = "%H:%M:%S")
x = format(as_datetime(dat$created_at), format = "%H:%M:%S")
table(x)
## logistic regression
dat <- read.csv('data/one_day.csv')
dat$created_at <- as.numeric(format(as_datetime(dat$created_at),
format = "%H:%M:%S"))
dat$timestamp <- as.numeric(format(as_datetime(dat$timestamp),
format = "%H:%M:%S"))
dat$updated_at <- as.numeric(format(as_datetime(dat$updated_at),
format = "%H:%M:%S"))
## logistic regression
dat <- read.csv('data/one_day.csv')
dat$created_at <- as.numeric(format(as_datetime(dat$created_at),
format = "%H:%M:%S"))
View(dat)
## logistic regression
dat <- read.csv('data/one_day.csv')
x = format(as_datetime(dat$created_at), format = "%H:%M:%S")
table(x)
## logistic regression
dat <- read.csv('data/one_day.csv')
dat$created_at <- as.numeric(format(as_datetime(dat$created_at),
format = "%H:%M:%S"))
x = format(as_datetime(dat$created_at), format = "%H:%M:%S")
table(x)
## logistic regression
dat <- read.csv('data/one_day.csv')
table(x)
## logistic regression
dat <- read.csv('data/one_day.csv')
x = format(as_datetime(dat$created_at), format = "%H:%M:%S")
table(x)
dat$created_at <- as.character(format(as_datetime(dat$created_at),
format = "%H:%M:%S"))
library(lubridate)
library(caret)
dat <- read.csv('data/one_day.csv')
dat$created_at <- as.character(format(as_datetime(dat$created_at),
format = "%H:%M:%S"))
dat$timestamp <- as.character(format(as_datetime(dat$timestamp),
format = "%H:%M:%S"))
dat$updated_at <- as.character(format(as_datetime(dat$updated_at),
format = "%H:%M:%S"))
dat$created_from <- NULL # Its only got one value
dat$project_id <- as.character(dat$project_id)
View(dat)
write.csv(dat, 'data/one_day_pp.csv')
dat$created_at <- as.character(format(as_datetime(dat$created_at),
format = "%H:%M"))
dat <- read.csv('data/one_day.csv')
dat$created_at <- as.character(format(as_datetime(dat$created_at),
format = "%H:%M"))
View(dat)
library(lubridate)
library(caret)
dat <- read.csv('data/one_day.csv')
dat$created_at <- as.character(format(as_datetime(dat$created_at),
format = "%H:%M"))
dat$timestamp <- as.character(format(as_datetime(dat$timestamp),
format = "%H:%M"))
dat$updated_at <- as.character(format(as_datetime(dat$updated_at),
format = "%H:%M"))
dat$created_from <- NULL # Its only got one value
dat$project_id <- as.character(dat$project_id)
write.csv(dat, 'data/one_day_pp.csv')
install.packages('devtools')
library(devtools)
install.packages('processx')
library(devtools)
devtools::check()
devtools::build()
